{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions import kl_divergence, Normal\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VanillaVAE and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class VanillaVAE(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, z1_dims, n_step, k=1000, num_layers=1, is_bidirection=True, is_training=True, is_cuda=False):\n",
    "        # z1: chroma+root\n",
    "        super(VanillaVAE, self).__init__()\n",
    "        self.input_dims = input_dims # only chroma\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.z1_dims = z1_dims\n",
    "        self.n_step = n_step\n",
    "        self.eps = 1\n",
    "        self.sample = None\n",
    "        self.iteration = 0\n",
    "        self.k = torch.FloatTensor([k])\n",
    "\n",
    "        self.training = is_training\n",
    "        self.is_cuda = is_cuda\n",
    "\n",
    "\n",
    "        self.hidden_factor = (2 if is_bidirection else 1) * num_layers\n",
    "        self.gru_0 = nn.GRU(input_dims, hidden_dims, batch_first=True, bidirectional=is_bidirection)\n",
    "        self.grucell_0 = nn.GRUCell(input_dims + z1_dims, hidden_dims)\n",
    "        self.mu = nn.Linear(hidden_dims * self.hidden_factor, z1_dims)\n",
    "        self.var = nn.Linear(hidden_dims * self.hidden_factor, z1_dims)\n",
    "        self.linear_init_0 = nn.Linear(z1_dims, hidden_dims)\n",
    "        self.linear_out_0 = nn.Linear(hidden_dims, input_dims)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def _sampling(self, x):\n",
    "        idx = x.max(1)[1]\n",
    "        x = torch.zeros_like(x)\n",
    "        arange = torch.arange(x.size(0)).long()\n",
    "        if torch.cuda.is_available():\n",
    "            arange = arange.cuda()\n",
    "        x[arange, idx] = 1\n",
    "        return x\n",
    "\n",
    "    def encoder(self, x):\n",
    "        _, x = self.gru_0(x)\n",
    "        x = x.transpose_(0,1).contiguous()\n",
    "        x = x.view(x.size(0), -1)\n",
    "        mean = self.mu(x)\n",
    "        stddev = (self.var(x) * 0.5).exp_()\n",
    "        return Normal(mean, stddev)\n",
    "\n",
    "    def decoder(self, z):\n",
    "        out = torch.zeros((z.size(0), self.input_dims)) # GRUcell's input and output\n",
    "        #print(out.shape)\n",
    "        out[:, -1] = 1 # ?\n",
    "        x = [] # final output\n",
    "        #print(z.size())\n",
    "        t = torch.tanh(self.linear_init_0(z))\n",
    "        hx = t\n",
    "        if self.is_cuda and torch.cuda.is_available():\n",
    "            out = out.cuda()\n",
    "        for i in range(self.n_step):\n",
    "            out = torch.cat([out, z], 1) # batch_size * (input_dims + z1_dims)\n",
    "            #print(out.shape)\n",
    "            hx = self.grucell_0(out, hx)\n",
    "            out = self.sigmoid(self.linear_out_0(hx)) # batch_size * input_dims\n",
    "            x.append(out)\n",
    "            if self.training:\n",
    "                p = torch.rand(1).item()\n",
    "                if p < self.eps:\n",
    "                    out = self.sample[:, i, :]\n",
    "                else:\n",
    "                    out = self._sampling(out)\n",
    "                self.eps = self.k / (self.k + torch.exp(self.iteration / self.k))\n",
    "                self.iteration += 1\n",
    "            else:\n",
    "                out = self._sampling(out)\n",
    "        return torch.stack(x, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            self.sample = x.clone()\n",
    "        latent = self.encoder(x)\n",
    "        if self.training:\n",
    "            z = latent.rsample()\n",
    "        else:\n",
    "            z = latent.mean\n",
    "        return self.decoder(z), latent.mean, latent.stddev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_normal(shape):\n",
    "    N = Normal(torch.zeros(shape), torch.ones(shape))\n",
    "    if torch.cuda.is_available():\n",
    "        N.loc = N.loc.cuda()\n",
    "        N.scale = N.scale.cuda()\n",
    "    return N\n",
    "\n",
    "def loss_function(recon, target_tensor, distribution, beta=.1):\n",
    "    BCE = F.binary_cross_entropy(recon, target_tensor, reduction='elementwise_mean')\n",
    "    normal = std_normal(distribution.mean.size())\n",
    "    KL = kl_divergence(distribution, normal).mean()\n",
    "    return BCE + beta * KL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 0\n",
    "NUM_EPOCHS = 200\n",
    "lr = 1e-3\n",
    "input_dims = 12\n",
    "hidden_dims = 800\n",
    "z1_dims = 128\n",
    "num_steps = 32\n",
    "is_cuda = True\n",
    "decay = 0.9999\n",
    "save_path = './ckpt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinExponentialLR(ExponentialLR):\n",
    "    def __init__(self, optimizer, gamma, minimum, last_epoch=-1):\n",
    "        self.min = minimum\n",
    "        super(MinExponentialLR, self).__init__(optimizer, gamma, last_epoch=-1)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [\n",
    "            max(base_lr * self.gamma**self.last_epoch, self.min)\n",
    "            for base_lr in self.base_lrs\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VanillaVAE(input_dims, hidden_dims, z1_dims, num_steps, is_cuda=is_cuda)\n",
    "if model.is_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "scheduler = MinExponentialLR(optimizer, gamma=decay, minimum=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('log/{}'.format('VanillaVAE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar8_cp_np = np.load('data/bar8_cp_np.npy')\n",
    "bar8_cp_tensor = torch.tensor(bar8_cp_np, dtype=torch.float32)\n",
    "trainset = bar8_cp_tensor[:6000]\n",
    "testset = bar8_cp_tensor[6000:]\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                        shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                        shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangzehao/.local/lib/python3.7/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cudnn RNN backward can only be called in training mode",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-fffd4f4f75e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m#torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cudnn RNN backward can only be called in training mode"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, targets in enumerate(trainloader):  \n",
    "        # Move tensors to the configured device\n",
    "        if model.cuda:\n",
    "            targets = targets.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        recons, means, stddevs = model(targets)\n",
    "        distribution = Normal(means, stddevs)\n",
    "        loss = loss_function(recons, targets, distribution)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        \n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print('batch loss: {:.5f}'.format(loss.item()))\n",
    "        writer.add_scalar('batch_loss', loss.item(), i)\n",
    "        \n",
    "        \n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.cpu().state_dict(), save_path+str(epoch)+'-epoch_VanillaVAE.ckpt')\n",
    "        if torch.cuda.is_available():\n",
    "            model.cuda()\n",
    "        print(epoch, '-epoch Model saved!')\n",
    "        print('test: ', test_recon(bar8_cp_tensor))\n",
    "        model.train()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final(recon):\n",
    "    return recon.apply_(lambda x: 1 if x>=0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    recons, _, _ = model(bar8_cp_tensor.cuda())\n",
    "    recons = get_final(recons.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_recon(targets):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        recons, _, _ = model(targets.cuda())\n",
    "        recons = get_final(recons.cpu())\n",
    "    size = recons.size()\n",
    "    amount = 1\n",
    "    for x in size:\n",
    "        amount *= x\n",
    "    return (torch.norm(recons-targets, 1)/amount).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6561, 32, 12])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recons.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2519424"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6561*32*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recons[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar8_cp_tensor[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_recon(bar8_cp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_recon(bar8_cp_tensor[:6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22756749391555786"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('ckpt_hidden=800_z=128/70-epoch_VanillaVAE.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VanillaVAE(\n",
       "  (gru_0): GRU(12, 800, batch_first=True, bidirectional=True)\n",
       "  (grucell_0): GRUCell(140, 800)\n",
       "  (mu): Linear(in_features=1600, out_features=128, bias=True)\n",
       "  (var): Linear(in_features=1600, out_features=128, bias=True)\n",
       "  (linear_init_0): Linear(in_features=128, out_features=800, bias=True)\n",
       "  (linear_out_0): Linear(in_features=800, out_features=12, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03971702232956886"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_recon(bar8_cp_tensor[6000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model = model.eval()\n",
    "    idx = 6401\n",
    "    target = bar8_cp_tensor[idx:idx+1][:][:]\n",
    "    recon,_,_ = model(target.cuda())\n",
    "    recon = get_final(recon.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True, False,  True,  True, False,  True, False,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon == target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
